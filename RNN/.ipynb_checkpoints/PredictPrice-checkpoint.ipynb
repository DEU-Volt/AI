{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_bp1ppCa3Ssd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv = pd.read_csv('train_data.csv')\n",
    "titles_csv = csv['title']\n",
    "prices_csv = csv['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52948 / 52948\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from konlpy.tag import Okt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    with open(\"dictionary.bin\", \"rb\") as f:\n",
    "        dictionary = pickle.load(f)\n",
    "    with open(\"titles_id.bin\", \"rb\") as f:\n",
    "        titles_id = pickle.load(f)\n",
    "        \n",
    "except Exception as e:\n",
    "    okt = Okt()\n",
    "    words_set = set()\n",
    "    titles_list = []\n",
    "    count = 1\n",
    "    for title in titles_csv:\n",
    "        title_pos = okt.pos(title, norm=True)\n",
    "        words_list = []\n",
    "        for words in title_pos:\n",
    "            words_set.add(words[0])\n",
    "            words_list.append(words[0])\n",
    "        titles_list.append(words_list)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"{count} / {len(titles_csv)}\")\n",
    "        count += 1\n",
    "        \n",
    "    dictionary = list(words_set)\n",
    "    titles_id = []\n",
    "    count = 1\n",
    "    for title in titles_list:\n",
    "        words_id = []\n",
    "        for words in title:\n",
    "            words_id.append(dictionary.index(words) + 1)\n",
    "        titles_id.append(words_id)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"{count} / {len(titles_list)}\")\n",
    "        count += 1\n",
    "        \n",
    "    with open(\"dictionary.bin\", \"wb\") as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "    with open(\"titles_id.bin\", \"wb\") as f:\n",
    "        pickle.dump(titles_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', '8', '부품', '용', '무선', '충전', '패드']\n",
      "[8012, 3828, 4560, 905, 3087, 6853, 7660]\n"
     ]
    }
   ],
   "source": [
    "print(titles_list[0])\n",
    "print(titles_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8410"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(dictionary)\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에너자이저\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[8410 - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlTu3tuBXhNH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainData, testData, trainResult, testResult = train_test_split(titles_id, prices)\n",
    "\n",
    "print(len(trainData))\n",
    "print(len(testData))\n",
    "print(len(trainResult))\n",
    "print(len(testResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ahQUo6qX3oP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(model_wv.vector_size, 64, weights=[trainData], trainable=False),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, recurrent_dropout=0.1)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainData, epochs=1, validation_data=testData, validation_steps=30, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
